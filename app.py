# app.py ‚Äî Chatbot Monty‚ÄØHall com Gemini¬†API e controle de contexto
# Autor: Tiago + ChatGPT | √öltima revis√£o: jul¬†2025

"""Resumo
---------
‚Ä¢ Mant√©m no m√°ximo `MAX_TURNS` trocas por sess√£o para evitar estouro de contexto.
‚Ä¢ Reinicia o chat automaticamente se atingir quota ou contexto (ResourceExhausted).
‚Ä¢ Usa vari√°vel de ambiente/secret **GOOGLE_API_KEY** para a chave.
"""

import os
import streamlit as st
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted

# ---------------- CONFIGURA√á√ÉO DA P√ÅGINA ---------------- #
st.set_page_config(page_title="Chat Monty Hall", page_icon="üé≤")
st.title("üêê Chatbot: Reflita sobre o Paradoxo de Monty Hall")

st.markdown(
    """
üëã **E a√≠! Eu sou o Monty, seu parceiro nessa miss√£o de decifrar o enigma das portas.**  

üö´ **Nada de resposta pronta**‚ÄÉ|‚ÄÉüéØ **E nem papo fora do assunto**  

S√≥ vou lan√ßar perguntas e pistas para provocar sua mente sobre o Problema de Monty‚ÄØHall.  

üí≠ **Bora come√ßar?** Mande sua primeira d√∫vida ou hip√≥tese!
"""
)

# ---------------- CHAVE DA API ---------------- #
API_KEY = os.getenv("GOOGLE_API_KEY")  # defina em secrets.toml ou no painel Secrets
if not API_KEY:
    st.error("Chave da API n√£o encontrada. Defina GOOGLE_API_KEY nos Secrets do Streamlit.")
    st.stop()

genai.configure(api_key=API_KEY)

# ---------------- PROMPT DE SISTEMA (PIAGETIANO) ---------------- #
system_instruction = (
    "Voc√™ √© um assistente educacional inspirado em Jean¬†Piaget. "
    "Ajude estudantes a refletir sobre o paradoxo de Monty‚ÄØHall fazendo perguntas que gerem desequil√≠brio cognitivo. "
    "Nunca forne√ßa a resposta direta. Se o aluno se aproximar da solu√ß√£o, incentive; se acertar, parabenize e pe√ßa justificativa. "
    "Nunca desvie do tema, mesmo que o usu√°rio tente. Mantenha tom gentil e instigante."
)

# ---------------- INICIALIZA MODELO ---------------- #
model = genai.GenerativeModel(
    model_name="models/gemini-1.5-flash-latest",
    system_instruction=system_instruction,
)

# ---------------- CONTROLE DE HIST√ìRICO ---------------- #
MAX_TURNS = 12  # n¬∫ m√°ximo de trocas antes de reiniciar

if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat()
    st.session_state.turns = 0

# ---------------- RENDERIZA HIST√ìRICO ---------------- #
for msg in st.session_state.chat.history:
    with st.chat_message(msg.role):
        st.markdown(msg.parts[0].text)

# ---------------- ENTRADA DO USU√ÅRIO ---------------- #
user_input = st.chat_input("Digite sua pergunta ou ideia sobre Monty Hall‚Ä¶")

if user_input:
    # Mostra mensagem do usu√°rio
    st.chat_message("user").markdown(user_input)

    # Incrementa contador de turnos e verifica limite
    st.session_state.turns += 1
    if st.session_state.turns > MAX_TURNS:
        st.session_state.chat = model.start_chat()
        st.session_state.turns = 1  # conta a intera√ß√£o atual

    # Tenta enviar mensagem, com captura de erro
    try:
        with st.chat_message("model"):
            response = st.session_state.chat.send_message(user_input)
            st.markdown(response.text)
    except ResourceExhausted:
        st.warning("Contexto ou quota excedidos; reiniciando a conversa para continuar.")
        st.session_state.chat = model.start_chat()
        st.session_state.turns = 1
        with st.chat_message("model"):
            response = st.session_state.chat.send_message(user_input)
            st.markdown(response.text)
